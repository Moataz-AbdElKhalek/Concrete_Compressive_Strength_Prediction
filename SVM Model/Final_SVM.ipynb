{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7G-PwPQ_9Ta7"
   },
   "outputs": [],
   "source": [
    "# Importing relevant modules\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "import sklearn.neural_network\n",
    "import sklearn.ensemble\n",
    "import sklearn.svm\n",
    "import sklearn.preprocessing\n",
    "import sklearn.metrics\n",
    "import scipy.stats\n",
    "\n",
    "\n",
    "# Ignoring warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nC4cZrt49WjO",
    "outputId": "d26dfca5-ae67-4718-8976-846b4545aa47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      X1     X2   X3     X4   X5      X6     X7     X8    y\n",
      "0  540.0    0.0  0.0  162.0  2.5  1040.0  676.0   28.0  1.0\n",
      "1  540.0    0.0  0.0  162.0  2.5  1055.0  676.0   28.0  1.0\n",
      "2  332.5  142.5  0.0  228.0  0.0   932.0  594.0  270.0  1.0\n",
      "3  332.5  142.5  0.0  228.0  0.0   932.0  594.0  365.0  1.0\n",
      "\n",
      "Dataset has 1030 rows and 9 columns\n",
      "\n",
      "0    1.0\n",
      "1    1.0\n",
      "2    1.0\n",
      "3    1.0\n",
      "Name: y, dtype: float64\n",
      "(1030,)\n",
      "\n",
      "      X1     X2   X3     X4   X5      X6     X7     X8\n",
      "0  540.0    0.0  0.0  162.0  2.5  1040.0  676.0   28.0\n",
      "1  540.0    0.0  0.0  162.0  2.5  1055.0  676.0   28.0\n",
      "2  332.5  142.5  0.0  228.0  0.0   932.0  594.0  270.0\n",
      "3  332.5  142.5  0.0  228.0  0.0   932.0  594.0  365.0\n",
      "(1030, 8)\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset:\n",
    "data_url = 'https://raw.githubusercontent.com/Moataz-AbdElKhalek/Concrete_Compressive_Strength_Prediction/main/dataset/Concrete_Dataset_Classification.csv'\n",
    "dataset = pd.read_csv(data_url)\n",
    "\n",
    "print(dataset.head(4))\n",
    "\n",
    "# Descriptive statistics\n",
    "print(\"\\nDataset has {} rows and {} columns\".format(dataset.shape[0],dataset.shape[1]))\n",
    "\n",
    "print()\n",
    "y = dataset['y']\n",
    "print(y.head(4))\n",
    "print(y.shape)\n",
    "print()\n",
    "\n",
    "X = dataset.drop(['y'], axis=1)\n",
    "print(X.head(4))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "4uRnAHP9_LYF",
    "outputId": "0623e30c-d0fa-40fe-a0f5-7bb7bdad6ead"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>281.167864</td>\n",
       "      <td>73.895825</td>\n",
       "      <td>54.188350</td>\n",
       "      <td>181.567282</td>\n",
       "      <td>6.204660</td>\n",
       "      <td>972.918932</td>\n",
       "      <td>773.580485</td>\n",
       "      <td>45.662136</td>\n",
       "      <td>-0.048544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.506364</td>\n",
       "      <td>86.279342</td>\n",
       "      <td>63.997004</td>\n",
       "      <td>21.354219</td>\n",
       "      <td>5.973841</td>\n",
       "      <td>77.753954</td>\n",
       "      <td>80.175980</td>\n",
       "      <td>63.169912</td>\n",
       "      <td>0.999306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>192.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>730.950000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>272.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>779.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>118.300000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>1029.400000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>540.000000</td>\n",
       "      <td>359.400000</td>\n",
       "      <td>200.100000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>992.600000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                X1           X2           X3           X4           X5  \\\n",
       "count  1030.000000  1030.000000  1030.000000  1030.000000  1030.000000   \n",
       "mean    281.167864    73.895825    54.188350   181.567282     6.204660   \n",
       "std     104.506364    86.279342    63.997004    21.354219     5.973841   \n",
       "min     102.000000     0.000000     0.000000   121.800000     0.000000   \n",
       "25%     192.375000     0.000000     0.000000   164.900000     0.000000   \n",
       "50%     272.900000    22.000000     0.000000   185.000000     6.400000   \n",
       "75%     350.000000   142.950000   118.300000   192.000000    10.200000   \n",
       "max     540.000000   359.400000   200.100000   247.000000    32.200000   \n",
       "\n",
       "                X6           X7           X8            y  \n",
       "count  1030.000000  1030.000000  1030.000000  1030.000000  \n",
       "mean    972.918932   773.580485    45.662136    -0.048544  \n",
       "std      77.753954    80.175980    63.169912     0.999306  \n",
       "min     801.000000   594.000000     1.000000    -1.000000  \n",
       "25%     932.000000   730.950000     7.000000    -1.000000  \n",
       "50%     968.000000   779.500000    28.000000    -1.000000  \n",
       "75%    1029.400000   824.000000    56.000000     1.000000  \n",
       "max    1145.000000   992.600000   365.000000     1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying statistical Analysis on the data:\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSiRrlOpGe0E"
   },
   "source": [
    "# **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "id": "U7WVJxbdGVRq",
    "outputId": "aacfec2d-5abc-4420-c92f-3724bb151939"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Attributes:\n",
      " Index(['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8'], dtype='object')\n",
      "\n",
      "Before Data Scaling:\n",
      "       X1     X2   X3     X4   X5      X6     X7     X8\n",
      "0  540.0    0.0  0.0  162.0  2.5  1040.0  676.0   28.0\n",
      "1  540.0    0.0  0.0  162.0  2.5  1055.0  676.0   28.0\n",
      "2  332.5  142.5  0.0  228.0  0.0   932.0  594.0  270.0\n",
      "3  332.5  142.5  0.0  228.0  0.0   932.0  594.0  365.0\n",
      "\n",
      "After Data Scaling:\n",
      "          X1        X2   X3        X4       X5        X6       X7        X8\n",
      "0  1.000000 -1.000000 -1.0 -0.357827 -0.84472  0.389535 -0.58856 -0.851648\n",
      "1  1.000000 -1.000000 -1.0 -0.357827 -0.84472  0.476744 -0.58856 -0.851648\n",
      "2  0.052511 -0.207012 -1.0  0.696486 -1.00000 -0.238372 -1.00000  0.478022\n",
      "3  0.052511 -0.207012 -1.0  0.696486 -1.00000 -0.238372 -1.00000  1.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.181882</td>\n",
       "      <td>-0.588782</td>\n",
       "      <td>-0.458387</td>\n",
       "      <td>-0.045251</td>\n",
       "      <td>-0.614617</td>\n",
       "      <td>-0.000471</td>\n",
       "      <td>-0.098944</td>\n",
       "      <td>-0.754604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.477198</td>\n",
       "      <td>0.480130</td>\n",
       "      <td>0.639650</td>\n",
       "      <td>0.341122</td>\n",
       "      <td>0.371046</td>\n",
       "      <td>0.452058</td>\n",
       "      <td>0.402288</td>\n",
       "      <td>0.347087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.587329</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.311502</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.238372</td>\n",
       "      <td>-0.312845</td>\n",
       "      <td>-0.967033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.219635</td>\n",
       "      <td>-0.877574</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.009585</td>\n",
       "      <td>-0.602484</td>\n",
       "      <td>-0.029070</td>\n",
       "      <td>-0.069242</td>\n",
       "      <td>-0.851648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.132420</td>\n",
       "      <td>-0.204508</td>\n",
       "      <td>0.182409</td>\n",
       "      <td>0.121406</td>\n",
       "      <td>-0.366460</td>\n",
       "      <td>0.327907</td>\n",
       "      <td>0.154039</td>\n",
       "      <td>-0.697802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                X1           X2           X3           X4           X5  \\\n",
       "count  1030.000000  1030.000000  1030.000000  1030.000000  1030.000000   \n",
       "mean     -0.181882    -0.588782    -0.458387    -0.045251    -0.614617   \n",
       "std       0.477198     0.480130     0.639650     0.341122     0.371046   \n",
       "min      -1.000000    -1.000000    -1.000000    -1.000000    -1.000000   \n",
       "25%      -0.587329    -1.000000    -1.000000    -0.311502    -1.000000   \n",
       "50%      -0.219635    -0.877574    -1.000000     0.009585    -0.602484   \n",
       "75%       0.132420    -0.204508     0.182409     0.121406    -0.366460   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                X6           X7           X8  \n",
       "count  1030.000000  1030.000000  1030.000000  \n",
       "mean     -0.000471    -0.098944    -0.754604  \n",
       "std       0.452058     0.402288     0.347087  \n",
       "min      -1.000000    -1.000000    -1.000000  \n",
       "25%      -0.238372    -0.312845    -0.967033  \n",
       "50%      -0.029070    -0.069242    -0.851648  \n",
       "75%       0.327907     0.154039    -0.697802  \n",
       "max       1.000000     1.000000     1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Scikit-learn MaxMinScaler: \n",
    "scaler = sklearn.preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# extract attributes and scale data to have Min = -1 and Max = 1 :\n",
    "cols = X.columns\n",
    "print('Data Attributes:\\n', cols)\n",
    "print('\\nBefore Data Scaling:\\n', X.head(4))\n",
    "sc_X = scaler.fit_transform(X) # Fit scaler to data, then transform data to specified feature_range(-1,1)\n",
    "\n",
    "# Turn the scaling results back into a dataframe :\n",
    "sc_X_df = pd.DataFrame(sc_X, columns = cols)\n",
    "X = sc_X_df\n",
    "print('\\nAfter Data Scaling:\\n', X.head(4))\n",
    "\n",
    "# Applying statistical Analysis on the data:\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztcmGU6RekFs"
   },
   "source": [
    "# **SVM Model Optimization**\n",
    "# Using 10-fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_ilicLtglRHf"
   },
   "outputs": [],
   "source": [
    "def SVM_CV(kernels,C_range,gamma_range):\n",
    "    \n",
    "  # Preparing the Model:\n",
    "  model = sklearn.svm.SVC(random_state=1)\n",
    "\n",
    "  # Determining Model Hyperparameters to be tested and optimized:\n",
    "  paras = {'kernel':kernels, 'C':C_range, 'gamma':gamma_range}\n",
    "\n",
    "  # Preparing Cross-Validation to be used to fit the Model and the Hyperparameters:\n",
    "  # Using 10-fold Cross-Validation:\n",
    "  gridCV = sklearn.model_selection.GridSearchCV(model, paras, cv=10, scoring='accuracy', verbose=10, n_jobs=-1)\n",
    "  gridCV.fit(X, y)\n",
    "\n",
    "  best_C = gridCV.best_params_['C']\n",
    "  best_gamma = gridCV.best_params_['gamma']\n",
    "  best_kernel = gridCV.best_params_['kernel']\n",
    "  best_score = gridCV.best_score_\n",
    "  results = gridCV.cv_results_\n",
    "\n",
    "  return best_C, best_gamma, best_kernel, best_score, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QN3NxcyrlSIH",
    "outputId": "e7ccae95-dead-4850-828e-6ee2e58acc91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 121 candidates, totalling 1210 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1927s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0962s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 156 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 260 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 320 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 380 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 448 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 516 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 592 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 668 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 752 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 836 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done 928 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1020 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1120 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (2.0610s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=-1)]: Done 1196 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1972s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done 1210 out of 1210 | elapsed:   19.3s finished\n"
     ]
    }
   ],
   "source": [
    "best_C, best_gamma, best_kernel, best_score, results = SVM_CV(['rbf'],numpy.logspace(-5, 5, 11),numpy.logspace(-5, 5, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1ykgP58ynFoE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_C = 100.0\n",
      "best_gamma = 1.0\n",
      "best_kernel = rbf\n",
      "Cross-Validation Mean Best Score for the Model = 0.8223300970873785\n",
      "\n",
      "Cross-Validation Mean Test Scores\n",
      " [0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.73398058 0.73106796 0.57087379 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.74466019 0.79320388\n",
      " 0.74854369 0.68932039 0.68252427 0.57087379 0.56893204 0.53203883\n",
      " 0.52427184 0.52427184 0.74660194 0.79902913 0.78932039 0.77281553\n",
      " 0.72135922 0.68543689 0.57087379 0.56990291 0.53203883 0.52427184\n",
      " 0.74563107 0.79514563 0.8038835  0.8        0.8223301  0.72330097\n",
      " 0.67961165 0.55825243 0.56990291 0.53203883 0.74563107 0.79320388\n",
      " 0.80776699 0.7961165  0.80679612 0.80194175 0.71553398 0.68349515\n",
      " 0.55825243 0.56990291 0.53203883 0.79223301 0.80970874 0.80873786\n",
      " 0.80679612 0.8184466  0.75242718 0.67669903 0.68349515 0.55825243\n",
      " 0.56990291 0.53203883 0.80873786 0.80970874 0.79320388 0.82135922\n",
      " 0.81067961 0.73300971 0.67184466 0.68349515 0.55825243 0.56990291\n",
      " 0.53203883]\n",
      "\n",
      "Split_1 Scores\n",
      " [0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.6407767  0.66019417 0.33009709 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.63106796 0.66019417\n",
      " 0.68932039 0.67961165 0.62135922 0.38834951 0.51456311 0.51456311\n",
      " 0.52427184 0.52427184 0.63106796 0.66990291 0.65048544 0.6407767\n",
      " 0.67961165 0.6407767  0.38834951 0.51456311 0.51456311 0.52427184\n",
      " 0.63106796 0.66990291 0.66019417 0.67961165 0.61165049 0.66990291\n",
      " 0.6407767  0.38834951 0.51456311 0.51456311 0.63106796 0.66990291\n",
      " 0.67961165 0.66990291 0.63106796 0.58252427 0.66990291 0.62135922\n",
      " 0.38834951 0.51456311 0.51456311 0.66990291 0.68932039 0.66990291\n",
      " 0.69902913 0.63106796 0.52427184 0.38834951 0.62135922 0.38834951\n",
      " 0.51456311 0.51456311 0.68932039 0.68932039 0.66019417 0.67961165\n",
      " 0.66019417 0.54368932 0.33980583 0.62135922 0.38834951 0.51456311\n",
      " 0.51456311]\n",
      "best_score (Split_1) = 0.6990291262135923\n",
      "\n",
      "Split_2 Scores\n",
      " [0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.99029126 0.91262136 0.51456311 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.99029126 0.95145631\n",
      " 0.81553398 0.69902913 0.55339806 0.54368932 0.54368932 0.54368932\n",
      " 0.52427184 0.52427184 0.99029126 0.94174757 0.74757282 0.67961165\n",
      " 0.60194175 0.52427184 0.54368932 0.54368932 0.54368932 0.52427184\n",
      " 0.99029126 0.95145631 0.89320388 0.65048544 0.73786408 0.61165049\n",
      " 0.52427184 0.50485437 0.54368932 0.54368932 0.99029126 0.95145631\n",
      " 0.93203883 0.6407767  0.67961165 0.66990291 0.62135922 0.57281553\n",
      " 0.50485437 0.54368932 0.54368932 0.94174757 0.93203883 0.88349515\n",
      " 0.6407767  0.67961165 0.61165049 0.61165049 0.57281553 0.50485437\n",
      " 0.54368932 0.54368932 0.93203883 0.93203883 0.63106796 0.67961165\n",
      " 0.69902913 0.59223301 0.61165049 0.57281553 0.50485437 0.54368932\n",
      " 0.54368932]\n",
      "best_score (Split_2) = 0.9902912621359223\n",
      "\n",
      "Split_3 Scores\n",
      " [0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.99029126 0.75728155 0.53398058 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 1.         0.87378641\n",
      " 0.80582524 0.59223301 0.59223301 0.49514563 0.57281553 0.57281553\n",
      " 0.52427184 0.52427184 1.         0.94174757 0.88349515 0.77669903\n",
      " 0.67961165 0.62135922 0.49514563 0.57281553 0.57281553 0.52427184\n",
      " 1.         0.95145631 0.9223301  0.87378641 0.85436893 0.7184466\n",
      " 0.62135922 0.41747573 0.57281553 0.57281553 1.         0.95145631\n",
      " 0.95145631 0.91262136 0.88349515 0.81553398 0.70873786 0.61165049\n",
      " 0.41747573 0.57281553 0.57281553 0.95145631 0.96116505 0.9223301\n",
      " 0.90291262 0.85436893 0.78640777 0.70873786 0.61165049 0.41747573\n",
      " 0.57281553 0.57281553 0.95145631 0.95145631 0.91262136 0.93203883\n",
      " 0.76699029 0.76699029 0.70873786 0.61165049 0.41747573 0.57281553\n",
      " 0.57281553]\n",
      "best_score (Split_3) = 1.0\n",
      "\n",
      "Split_4 Scores\n",
      " [0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.36893204 0.44660194 0.40776699 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.37864078 0.61165049\n",
      " 0.59223301 0.4368932  0.52427184 0.42718447 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.38834951 0.60194175 0.67961165 0.68932039\n",
      " 0.52427184 0.50485437 0.42718447 0.52427184 0.52427184 0.52427184\n",
      " 0.38834951 0.5631068  0.63106796 0.72815534 0.74757282 0.54368932\n",
      " 0.50485437 0.42718447 0.52427184 0.52427184 0.38834951 0.5631068\n",
      " 0.63106796 0.72815534 0.67961165 0.65048544 0.5631068  0.52427184\n",
      " 0.42718447 0.52427184 0.52427184 0.5631068  0.63106796 0.65048544\n",
      " 0.7184466  0.69902913 0.59223301 0.55339806 0.52427184 0.42718447\n",
      " 0.52427184 0.52427184 0.63106796 0.62135922 0.72815534 0.7184466\n",
      " 0.66990291 0.57281553 0.55339806 0.52427184 0.42718447 0.52427184\n",
      " 0.52427184]\n",
      "best_score (Split_4) = 0.7475728155339806\n",
      "\n",
      "Split_5 Scores\n",
      " [0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.59223301 0.67961165 0.54368932 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.61165049 0.77669903\n",
      " 0.7961165  0.69902913 0.61165049 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.62135922 0.76699029 0.76699029 0.7961165\n",
      " 0.7961165  0.6407767  0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.62135922 0.76699029 0.76699029 0.80582524 0.84466019 0.76699029\n",
      " 0.6407767  0.52427184 0.52427184 0.52427184 0.62135922 0.75728155\n",
      " 0.75728155 0.78640777 0.81553398 0.83495146 0.76699029 0.6407767\n",
      " 0.52427184 0.52427184 0.52427184 0.75728155 0.76699029 0.77669903\n",
      " 0.83495146 0.84466019 0.78640777 0.76699029 0.6407767  0.52427184\n",
      " 0.52427184 0.52427184 0.76699029 0.75728155 0.78640777 0.82524272\n",
      " 0.84466019 0.78640777 0.76699029 0.6407767  0.52427184 0.52427184\n",
      " 0.52427184]\n",
      "best_score (Split_5) = 0.8446601941747572\n",
      "\n",
      "Split_6 Scores\n",
      " [0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.63106796 0.65048544 0.54368932 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.65048544 0.72815534\n",
      " 0.73786408 0.7184466  0.72815534 0.53398058 0.53398058 0.52427184\n",
      " 0.52427184 0.52427184 0.65048544 0.73786408 0.77669903 0.77669903\n",
      " 0.72815534 0.7184466  0.53398058 0.53398058 0.52427184 0.52427184\n",
      " 0.65048544 0.73786408 0.76699029 0.80582524 0.7961165  0.67961165\n",
      " 0.70873786 0.53398058 0.53398058 0.52427184 0.65048544 0.73786408\n",
      " 0.76699029 0.7961165  0.86407767 0.80582524 0.67961165 0.69902913\n",
      " 0.53398058 0.53398058 0.52427184 0.73786408 0.77669903 0.76699029\n",
      " 0.7961165  0.85436893 0.7961165  0.61165049 0.69902913 0.53398058\n",
      " 0.53398058 0.52427184 0.76699029 0.77669903 0.7961165  0.85436893\n",
      " 0.80582524 0.78640777 0.61165049 0.69902913 0.53398058 0.53398058\n",
      " 0.52427184]\n",
      "best_score (Split_6) = 0.8640776699029126\n",
      "\n",
      "Split_7 Scores\n",
      " [0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.91262136 0.90291262 0.49514563 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.91262136 0.9223301\n",
      " 0.67961165 0.50485437 0.59223301 0.53398058 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.91262136 0.93203883 0.93203883 0.7961165\n",
      " 0.55339806 0.57281553 0.53398058 0.52427184 0.52427184 0.52427184\n",
      " 0.91262136 0.93203883 0.94174757 0.85436893 0.81553398 0.57281553\n",
      " 0.57281553 0.52427184 0.52427184 0.52427184 0.91262136 0.93203883\n",
      " 0.94174757 0.93203883 0.86407767 0.85436893 0.57281553 0.59223301\n",
      " 0.52427184 0.52427184 0.52427184 0.93203883 0.94174757 0.94174757\n",
      " 0.89320388 0.91262136 0.75728155 0.55339806 0.59223301 0.52427184\n",
      " 0.52427184 0.52427184 0.94174757 0.94174757 0.93203883 0.87378641\n",
      " 0.87378641 0.66990291 0.55339806 0.59223301 0.52427184 0.52427184\n",
      " 0.52427184]\n",
      "best_score (Split_7) = 0.941747572815534\n",
      "\n",
      "Split_8 Scores\n",
      " [0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.66990291 0.6407767  0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.66019417 0.73786408\n",
      " 0.6407767  0.67961165 0.73786408 0.55339806 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.66019417 0.72815534 0.74757282 0.77669903\n",
      " 0.75728155 0.76699029 0.55339806 0.53398058 0.52427184 0.52427184\n",
      " 0.66019417 0.73786408 0.76699029 0.81553398 0.89320388 0.74757282\n",
      " 0.72815534 0.55339806 0.53398058 0.52427184 0.66019417 0.73786408\n",
      " 0.76699029 0.77669903 0.84466019 0.86407767 0.6407767  0.72815534\n",
      " 0.55339806 0.53398058 0.52427184 0.73786408 0.76699029 0.77669903\n",
      " 0.81553398 0.88349515 0.72815534 0.6407767  0.72815534 0.55339806\n",
      " 0.53398058 0.52427184 0.77669903 0.77669903 0.77669903 0.85436893\n",
      " 0.87378641 0.68932039 0.6407767  0.72815534 0.55339806 0.53398058\n",
      " 0.52427184]\n",
      "best_score (Split_8) = 0.8932038834951457\n",
      "\n",
      "Split_9 Scores\n",
      " [0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.81553398 0.82524272 0.86407767 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.82524272 0.83495146\n",
      " 0.86407767 0.90291262 0.87378641 0.86407767 0.7184466  0.53398058\n",
      " 0.52427184 0.52427184 0.82524272 0.84466019 0.83495146 0.90291262\n",
      " 0.91262136 0.87378641 0.86407767 0.7184466  0.53398058 0.52427184\n",
      " 0.82524272 0.82524272 0.85436893 0.88349515 0.95145631 0.94174757\n",
      " 0.86407767 0.86407767 0.7184466  0.53398058 0.82524272 0.82524272\n",
      " 0.82524272 0.83495146 0.90291262 0.96116505 0.95145631 0.85436893\n",
      " 0.86407767 0.7184466  0.53398058 0.82524272 0.81553398 0.85436893\n",
      " 0.88349515 0.89320388 0.96116505 0.95145631 0.85436893 0.86407767\n",
      " 0.7184466  0.53398058 0.81553398 0.82524272 0.83495146 0.88349515\n",
      " 0.94174757 0.94174757 0.95145631 0.85436893 0.86407767 0.7184466\n",
      " 0.53398058]\n",
      "best_score (Split_9) = 0.9611650485436893\n",
      "\n",
      "Split_10 Scores\n",
      " [0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184 0.52427184\n",
      " 0.72815534 0.83495146 0.95145631 0.52427184 0.52427184 0.52427184\n",
      " 0.52427184 0.52427184 0.52427184 0.52427184 0.78640777 0.83495146\n",
      " 0.86407767 0.98058252 0.99029126 0.84466019 0.70873786 0.53398058\n",
      " 0.52427184 0.52427184 0.78640777 0.82524272 0.87378641 0.89320388\n",
      " 0.98058252 0.99029126 0.84466019 0.70873786 0.53398058 0.52427184\n",
      " 0.77669903 0.81553398 0.83495146 0.90291262 0.97087379 0.98058252\n",
      " 0.99029126 0.84466019 0.70873786 0.53398058 0.77669903 0.80582524\n",
      " 0.82524272 0.88349515 0.90291262 0.98058252 0.98058252 0.99029126\n",
      " 0.84466019 0.70873786 0.53398058 0.80582524 0.81553398 0.84466019\n",
      " 0.88349515 0.93203883 0.98058252 0.98058252 0.99029126 0.84466019\n",
      " 0.70873786 0.53398058 0.81553398 0.82524272 0.87378641 0.91262136\n",
      " 0.97087379 0.98058252 0.98058252 0.99029126 0.84466019 0.70873786\n",
      " 0.53398058]\n",
      "best_score (Split_10) = 0.9902912621359223\n"
     ]
    }
   ],
   "source": [
    "print('best_C =',best_C)\n",
    "print('best_gamma =',best_gamma)\n",
    "print('best_kernel =', best_kernel)\n",
    "print('Cross-Validation Mean Best Score for the Model =',best_score)\n",
    "print('\\nCross-Validation Mean Test Scores\\n', results['mean_test_score'])\n",
    "\n",
    "for i in range(10):\n",
    "  print('\\nSplit_'+str(i+1)+' Scores\\n',results['split'+str(i)+'_test_score'])\n",
    "  print('best_score (Split_'+str(i+1)+') =', max(results['split'+str(i)+'_test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CEBMi3IWeKVm"
   },
   "source": [
    "# **Data Fixed Single Splitting**\n",
    "(70% Training and 30% Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bcECmcqO-P9p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(721, 8)\n",
      "(721,)\n",
      "(309, 8)\n",
      "(309,)\n"
     ]
    }
   ],
   "source": [
    "# Dividing samples dataset into training and test datasets:\n",
    "def dataset_divide(X, y):\n",
    "  X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, train_size=0.70, random_state=1)\n",
    "  return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = dataset_divide(X,y)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Nw7_6EFewX7"
   },
   "source": [
    "# **SVM Final Optimized Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FUTp-yVDe0NY"
   },
   "outputs": [],
   "source": [
    "# SVM Classification Model:\n",
    "def SVM_Classification(X,y, best_kernel='rbf', C_optimum = 100, gamma_optimum = 1):\n",
    "  model = sklearn.svm.SVC(kernel= best_kernel, C = C_optimum, gamma = gamma_optimum, random_state=1)\n",
    "  model.fit(X, y)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "a51oIpime1zh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of Model Evaluation with Testing Data = 0.8446601941747572\n",
      "rmse_test =  0.7882634225314344\n",
      "pcc_test =  0.689361885866495\n",
      "scc_test =  0.6893618858664952\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of Model Evaluation with Training Data = 0.9805825242718447\n",
      "rmse_train =  0.2786932057166471\n",
      "pcc_train =  0.9610457626727164\n",
      "scc_train =  0.9610457626727165\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SVM Classification Model Training:\n",
    "SVM_Model = SVM_Classification(X_train, y_train)\n",
    "\n",
    "# SVM Classification Model Evaluation on Testing Data:\n",
    "current_score = SVM_Model.score(X_test,y_test)\n",
    "y_test_hat = SVM_Model.predict(X_test) # testing output\n",
    "\n",
    "print('Score of Model Evaluation with Testing Data =', current_score)\n",
    "# RMSE\n",
    "rmse_test = sklearn.metrics.mean_squared_error(y_test, y_test_hat, squared=False)\n",
    "print('rmse_test = ',rmse_test)\n",
    "\n",
    "# Pearson's correlation\n",
    "pcc_test = scipy.stats.pearsonr(y_test, y_test_hat)[0]\n",
    "print ('pcc_test = ', pcc_test)\n",
    "\n",
    "#Spearman's correlation\n",
    "scc_test = scipy.stats.spearmanr(y_test, y_test_hat)[0]\n",
    "print ('scc_test = ', scc_test)\n",
    "\n",
    "matplotlib.pyplot.scatter(y_test,y_test_hat)\n",
    "matplotlib.pyplot.show()\n",
    "\n",
    "# SVM Classification Model Evaluation on Training Data:\n",
    "current_score = SVM_Model.score(X_train,y_train)\n",
    "y_train_hat = SVM_Model.predict(X_train) # testing output\n",
    "\n",
    "print('Score of Model Evaluation with Training Data =', current_score)\n",
    "# RMSE\n",
    "rmse_train = sklearn.metrics.mean_squared_error(y_train, y_train_hat, squared=False)\n",
    "print('rmse_train = ',rmse_train)\n",
    "# Pearson's correlation\n",
    "pcc_train = scipy.stats.pearsonr(y_train, y_train_hat)[0]\n",
    "print ('pcc_train = ', pcc_train)\n",
    "\n",
    "#Spearman's correlation\n",
    "scc_train = scipy.stats.spearmanr(y_train, y_train_hat)[0]\n",
    "print ('scc_train = ', scc_train)\n",
    "\n",
    "matplotlib.pyplot.scatter(y_train,y_train_hat)\n",
    "matplotlib.pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Final_SVM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
